{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXzyQV84qqcWzUGqbGnOFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yueop/AS_LAB/blob/main/train_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssFeavU5io5K",
        "outputId": "75e48014-f0be-40e7-cf29-2a46eeea66d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "현재 위치: /content/drive/MyDrive/AS_LAB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. 드라이브 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. 경로 설정\n",
        "PROJECT_PATH = '/content/drive/MyDrive/AS_LAB'\n",
        "if not os.path.exists(PROJECT_PATH):\n",
        "    os.makedirs(PROJECT_PATH)\n",
        "\n",
        "# 3. 시스템 경로 추가 및 작업 디렉토리 변경\n",
        "if PROJECT_PATH not in sys.path:\n",
        "    sys.path.append(PROJECT_PATH)\n",
        "os.chdir(PROJECT_PATH)\n",
        "\n",
        "print(f\"현재 위치: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 이름을 명시적으로 지정\n",
        "FILE_NAME = \"train.py\"\n",
        "# 전체 경로 사용\n",
        "SAVE_PATH = f\"/content/drive/MyDrive/AS_LAB/{FILE_NAME}\""
      ],
      "metadata": {
        "id": "vt7rLFhaizpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import yaml\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "#1. 데이터 로더 및 get_model함수 임포트\n",
        "from my_datasets import UnifiedDataLoader\n",
        "from models import get_model\n",
        "\n",
        "#config 파일을 읽어 딕셔너리로 변환하는 함수\n",
        "def load_config(config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    return config\n",
        "\n",
        "#시드 고정해주는 함수(재현성 확보를 위해 구현)\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed) #CPU 연산 시드 고정\n",
        "    np.random.seed(seed) #NumPy 연산 시드 고정\n",
        "    random.seed(seed) #Python 기본 랜덤 시드 고정\n",
        "    if torch.cuda.is_available(): #GPU가 있다면\n",
        "        torch.cuda.manual_seed(seed) #GPU 연산 시드 고정\n",
        "        torch.cuda.manual_seed_all(seed) #멀티 GPU라면 전체 연산 시드 고정\n",
        "\n",
        "#loss/accuracy curve 그리는 함수\n",
        "def plot_curve(history, save_dir):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    #1. loss 그래프\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history['train_loss'], label='Train Loss', color='blue')\n",
        "    plt.plot(epochs, history['val_loss'], label='Val Loss', color='red')\n",
        "    plt.title('Loss Curve')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    #2. Accuracy 그래프\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history['train_acc'], label='Train Acc', color='blue')\n",
        "    plt.plot(epochs, history['val_acc'], label='Val Acc', color='red')\n",
        "    plt.title('Accuracy Curve')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    #저장\n",
        "    save_path = os.path.join(save_dir, 'learning_curve.png')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"학습 그래프가 저장되었습니다: {save_path}\")\n",
        "\n",
        "#Val Loss가 더 이상 줄어들지 않으면 학습을 강제 종료하는 클래스\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, path='checkpoint.pth'):\n",
        "        self.patience = patience #Val Loss가 줄어들지 않아도 참아주는 횟수\n",
        "        self.verbose = verbose #로그 출력 여부\n",
        "        self.counter = 0 #Val Loss가 줄어들지 않은 횟수 카운터\n",
        "        self.best_score = None #현재 최고 점수\n",
        "        self.early_stop = False #Early Stopping 신호\n",
        "        self.val_loss_min = np.inf #최소 Val Loss 기록(초기 값은 무한대: 첫 번째 epoch의 결과값을 무조건 최고기록으로 저장하기 위해)\n",
        "        self.path = path #모델 저장 경로\n",
        "\n",
        "    def __call__(self, val_loss, model): #객체 실행 함수(매 Epoch마다 실행)\n",
        "        score = -val_loss #loss가 낮으면 점수가 높게 설정\n",
        "        if self.best_score is None: #첫 번째 epoch인 경우\n",
        "            self.best_score = score #현재 점수를 최고 점수로 저장\n",
        "            self.save_checkpoint(val_loss, model) #모델 저장\n",
        "        elif score < self.best_score: #성능 개선 실패할 경우\n",
        "            self.counter += 1 #카운트 1 증가\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience: #참는 횟수 초과 시\n",
        "                self.early_stop = True #종료 신호 켜기\n",
        "        else: #성능 개선 성공한 경우\n",
        "            self.best_score = score #최고 점수 갱신\n",
        "            self.save_checkpoint(val_loss, model) #모델 저장\n",
        "            self.counter = 0 #카운트 초기화\n",
        "\n",
        "    #모델의 가중치 파일로 저장하는 함수\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        if self.verbose:\n",
        "            print(f'Loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). 모델을 저장합니다...')\n",
        "        torch.save(model.state_dict(), self.path) #state_dict(가중치) 저장\n",
        "        self.val_loss_min = val_loss #최소 loss 갱신\n",
        "\n",
        "#메인 함수\n",
        "def main():\n",
        "    #1. 시드 및 설정 로드\n",
        "    cfg = load_config('config.yaml') #config 파일 불러오기\n",
        "    set_seed(cfg['train']['seed']) #시드 고정(config 파일에 지정해둔 시드)\n",
        "    aug_config = cfg['data'].get('augmentation', {'use_aug': False})\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    base_dir = os.getcwd() #저장 경로 절대 경로로 반환\n",
        "    result_dir = os.path.join(base_dir, 'results', cfg['project_name'])\n",
        "    if not os.path.exists(result_dir):\n",
        "        os.makedirs(result_dir)\n",
        "    save_path = os.path.join(base_dir, cfg['train']['save_path'])\n",
        "    print(f\"device: {device} | model: {cfg['model']['type']}\")\n",
        "\n",
        "    #2. 데이터 로더\n",
        "    data_loader = UnifiedDataLoader(cfg) #통합 데이터 로더 객체 생성\n",
        "    train_loader = data_loader.get_loader(cfg['data']['dataset_name'], 'train') #학습용 로더 가져오기\n",
        "    val_loader = data_loader.get_loader(cfg['data']['dataset_name'], 'val') #검증용 로더 가져오기\n",
        "\n",
        "    #3. 모델 초기화(설정 파일 값들을 이용해 모델 생성)\n",
        "    dropout_rate = cfg['model'].get('dropout_rate', 0.0) #Dropout 확률 설정\n",
        "    model = get_model(\n",
        "        cfg['model']['type'],\n",
        "        cfg['model']['input_size'],\n",
        "        cfg['model']['hidden_size'],\n",
        "        cfg['model']['num_classes'],\n",
        "        dropout_rate = dropout_rate\n",
        "    )\n",
        "    model = model.to(device) #모델을 선택된 장치 메모리로 이동\n",
        "\n",
        "    #4. 학습 도구 설정\n",
        "    #Optimizer 선택 및 weight decay 적용\n",
        "    lr = cfg['train']['learning_rate']\n",
        "    weight_decay = cfg['train'].get('weight_decay', 0.0) #과적합 방지용(정답 외우는 방식 사용하면 감점)\n",
        "    optimizer_name = cfg['train'].get('optimizer', 'adam') #optimizer 설정값이 있으면 설정된 기법, 없으면 Adam 기법\n",
        "\n",
        "    if optimizer_name.lower() == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    #스케줄러 설정\n",
        "    scheduler = None\n",
        "    if cfg['train'].get('use_scheduler', False):\n",
        "        step_size = cfg['train'].get('scheduler_step', 10)\n",
        "        gamma = cfg['train'].get('scheduler_gamma', 0.1)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "        print(f\"Scheduler Activated: StepLR (step={step_size}, gamma={gamma})\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss() #손실 함수: 다중 분류용 엔트로피(예측과 정답을 비교해서 점수(벌점) 매기는 함수)\n",
        "    early_stopping = EarlyStopping(patience=cfg['train']['patience'], verbose=True, path=cfg['train']['save_path']) #Early Stopping 도구 준비\n",
        "\n",
        "    #기록 저장용 딕셔너리\n",
        "    history = {\n",
        "        'train_loss' : [],\n",
        "        'train_acc' : [],\n",
        "        'val_loss' : [],\n",
        "        'val_acc' : []\n",
        "    }\n",
        "\n",
        "    #5. 학습 루프 시작\n",
        "    epochs = cfg['train']['num_epochs'] #전체 반복 세대 수\n",
        "    print('학습을 시작합니다...')\n",
        "\n",
        "    train_time = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time() #시간 측정 시작(Epoch 시작 직전)\n",
        "        #train\n",
        "        model.train() #모델을 학습 모드로 전환()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_total +=labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        end_time = time.time() #시간 측정 종료(Train Loop 종료시)\n",
        "        epoch_duration = end_time - start_time #소요 시간 계산(초 단위)\n",
        "\n",
        "        #평균 Loss 및 정확도 계산\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_train_acc = train_correct / train_total\n",
        "\n",
        "        #validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        #계산\n",
        "        epoch_duration = time.time() - start_time\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_train_acc = train_correct / train_total\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_acc = val_correct / val_total\n",
        "        train_time += epoch_duration\n",
        "\n",
        "        #history 저장\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['train_acc'].append(avg_train_acc)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        #스케줄러 업데이트\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "              f\"Time: {epoch_duration:.2f}s | \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f} Train Acc: {avg_train_acc:.4f} | \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f} Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        #Early Stopping 확인\n",
        "        early_stopping(avg_val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early Stopping이 작동되었습니다.\")\n",
        "            break\n",
        "\n",
        "    print(f\"학습이 종료되었습니다. | 학습 시간: {train_time}\")\n",
        "\n",
        "    #결과 저장\n",
        "    json_path = os.path.join(result_dir, 'history.json')\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(history, f)\n",
        "    #그래프 그리기\n",
        "    plot_curve(history, save_dir=result_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\"\n",
        "try:\n",
        "    with open(SAVE_PATH, 'w', encoding='utf-8') as f:\n",
        "        f.write(content.strip())\n",
        "    print(f\"파일이 안전하게 생성되었습니다: {SAVE_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"저장 실패: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNRYDKTHi3m2",
        "outputId": "e7484211-76ca-42c9-d7f8-54cc022d86d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일이 안전하게 생성되었습니다: /content/drive/MyDrive/AS_LAB/train.py\n"
          ]
        }
      ]
    }
  ]
}